<!doctype html>
<html>
<head>
    <title> Interactive and Automatic Navigation for 360° Video Playback </title>
</head>

<!-- <LINK media=all href= "../glab.css" type=text/css rel=StyleSheet>
<STYLE type=text/css media=all>
#primarycontent {
    MARGIN-LEFT: auto; ; WIDTH: expression(document.body.clientWidth >
800? "800px": "auto" ); MARGIN-RIGHT: auto; TEXT-ALIGN: left; max-width:
800px }
BODY {
    TEXT-ALIGN: center
}
.style1 {font-size: x-small}
</STYLE> -->

<body class="wide">
<DIV id=primarycontent>
<H1 align="center"> Interactive and Automatic Navigation for 360° Video Playback </H1>
<!-- Author header -->
  <table width="90%" border="0" align="center" cellpadding="0" cellspacing="3">
    <tr>
        <td><p align="center"><a href=https://kyoungkookkang.github.io/ target="_blank">Kyoungkook Kang</a><br>DGIST</p></td>
        <td><p align="center"><a href=https://vclab.dgist.ac.kr/scho/ target="_blank">Sunghyun Cho</a><br>DGIST</p></td>
    </tr>
    <tr>
      <td colspan="5">      <p align="center"><strong> ACM Transactions on Graphics, vol. 38, no. 4, Article 108 (SIGGRAPH 2019) </strong></p><br></td>
    </tr>
  </table><br>

<!-- Teasure -->
<table>
    <table width="95%" border="0" align="center" cellpadding="0" cellspacing="0">
    <tr>
        <td><img src=../Project/SIG_2019_Interactive360/teaser.jpg width=95%></td></tr>
</table><br>

<!-- body -->
    <table width = "95%" border="0" align="center" cellpadding="0" cellspacing="5">
        <tr>
            <td width="70%"><h2 align="left">Abstract</h2>
                <p align="justify"> A common way to view a 360° video on a 2D display is to crop and render a part of the video as a normal field-of-view (NFoV) video. While users can enjoy natural-looking NFoV videos using this approach, they need to constantly make manual adjustment of the viewing direction not to miss interesting events in the video. In this paper, we propose an interactive and automatic navigation system for comfortable 360° video playback. Our system finds a virtual camera path that shows the most salient areas through the video, generates a NFoV video based on the path, and plays it in an online manner. A user can interactively change the viewing direction while watching a video, and the system instantly updates the path reflecting the intention of the user. To enable online processing, we design our system consisting of an offline pre-processing step, and an online 360° video navigation step. The pre-processing step computes optical flow and saliency scores for an input video. Based on these, the online video navigation step computes an optimal camera path reflecting user interaction, and plays a NFoV video in an online manner. For improved user experience, we also introduce optical flow-based camera path planning, saliency-aware path update, and adaptive control of the temporal window size. Our experimental results including user studies show that our system provides more pleasant experience of watching 360° videos than existing approaches.</p></td>
            <td width="30%" rowspan="3" valign="top"><br>
                <table width="95%" border="0" align="right" cellpadding="0" cellspacing="6">
                <tr>
<td><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12875">Paper (Wiley Online Library)</a>
</td></tr>
<tr>
<td><a href="https://github.com/JunhoJeon/interval_gradient">Source code (github)</a>
</td>
</tr>
<tr><td width=50%><div align="right"></td></tr>
<tr><td width=50%><div align="right"></td></tr>
</tr>
            </table>
            </td>
        </tr>
        <tr>
        <td>
          <!-- <table align="middle"> <tr> <td> <a href="http://coupe.postech.ac.kr"> <img src="../coupelogo.png"> </a> </td> <td> see the new features in coupe website  <a href="http://coupe.postech.ac.kr"> [link] </td></tr> </a> </table> -->
        </td>
        </tr>
    </table>

</DIV>
</body></html>
